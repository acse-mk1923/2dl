{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1sT1tAPqLzl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import csv\n",
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from genericpath import isdir\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "from sympy import false\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch"
      ],
      "metadata": {
        "id": "y9FR6xkVqdRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "root_dir = \"/content/drive/MyDrive/Selected_Storms_curated\"\n",
        "\n",
        "path_to_append = '/content/drive/MyDrive'\n",
        "\n",
        "if path_to_append in sys.path:\n",
        "    print('Path already present')\n",
        "else:\n",
        "    sys.path.append(path_to_append)\n",
        "    print('Path appended to sys')\n",
        "\n",
        "from Utility_funcs.window_dataloader import StormDataLoader, StormDataset"
      ],
      "metadata": {
        "id": "NLmWWqWrqfvV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "781ee20e-1f14-4721-c78a-2a674eb7709c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Path appended to sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kF9lNHZqLzm"
      },
      "outputs": [],
      "source": [
        "# class StormDataset(Dataset):\n",
        "#     def __init__(self, root: str, storm: str, sequence_length: int, alldata=False) -> None:\n",
        "#         self.sequence_length = sequence_length\n",
        "#         self.prefix = root\n",
        "#         self.storm_name = storm\n",
        "\n",
        "#        # 图像预处理转换\n",
        "#         self.transform = transforms.Compose([\n",
        "#             transforms.Resize((128, 128)),\n",
        "#             transforms.CenterCrop((128, 128)),\n",
        "#             transforms.ToTensor(),\n",
        "#             transforms.Normalize(mean=[0.485], std=[0.229]),\n",
        "#         ])\n",
        "\n",
        "\n",
        "#         # 加载数据并预处理\n",
        "#         self.data, self.preprocessed_images = self._load_data()\n",
        "\n",
        "#         # 时间缩放器\n",
        "#         self.time_scaler = MinMaxScaler()\n",
        "#         self.data['Relative_Time'] = self.time_scaler.fit_transform(self.data[['Relative_Time']])\n",
        "#         self.data['Time_Diff'] = self.data['Relative_Time'].diff()\n",
        "#         self.data['Time_Diff'].fillna(0, inplace=True)\n",
        "\n",
        "#     def _load_data(self):\n",
        "#         datalist = []\n",
        "#         preprocessed_images = {}\n",
        "\n",
        "#         # storm_dir = os.path.join(self.prefix, self.storm_name)\n",
        "#         # if os.path.isdir(storm_dir):\n",
        "#         #     image_files = [file for file in os.listdir(storm_dir) if file.endswith((\".jpg\", \".jpeg\"))]\n",
        "#         #     for im in image_files:\n",
        "#         storm_dir = os.path.join(self.prefix, self.storm_name)\n",
        "#         if os.path.isdir(storm_dir):\n",
        "#             image_files = [file for file in os.listdir(storm_dir) if file.endswith((\".jpg\", \".jpeg\"))]\n",
        "#             for im in image_files:\n",
        "\n",
        "#                 split_names = re.split(r\"[_.]\", im)\n",
        "#                 split_names = [part for part in split_names if part]\n",
        "#                 name, num = split_names[0], split_names[1]\n",
        "\n",
        "#                 # 加载并预处理图像\n",
        "#                 image_path = os.path.join(storm_dir, im)\n",
        "\n",
        "#                 image = Image.open(image_path)\n",
        "#                 preprocessed_images[num] = self.transform(image)\n",
        "\n",
        "\n",
        "#                 # 读取 JSON 数据\n",
        "#                 json_data = self._load_json(os.path.join(storm_dir, name + \"_\" + num))\n",
        "#                 json_data[\"Id\"] = num\n",
        "#                 datalist.append(json_data)\n",
        "\n",
        "#         return pd.DataFrame(datalist), preprocessed_images\n",
        "\n",
        "#     def _load_json(self, file_prefix):\n",
        "#         with open(file_prefix + \"_label.json\", \"r\") as json_file:\n",
        "#             label_data = json.load(json_file)\n",
        "#         with open(file_prefix + \"_features.json\", \"r\") as json_file:\n",
        "#             features_data = json.load(json_file)\n",
        "\n",
        "#         return {\n",
        "#             \"Storm_Name\": features_data[\"storm_id\"],\n",
        "#             \"Wind_Speed\": int(label_data[\"wind_speed\"]),\n",
        "#             \"Relative_Time\": int(features_data[\"relative_time\"]),\n",
        "#             \"Ocean\": int(features_data[\"ocean\"]),\n",
        "#             \"Image_Path\": file_prefix + \".jpg\",\n",
        "#         }\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data) - self.sequence_length\n",
        "\n",
        "#     # def __getitem__(self, idx):\n",
        "#         # if idx + self.sequence_length >= len(self.data):\n",
        "#         #     idx = len(self.data) - self.sequence_length - 1\n",
        "\n",
        "#         # sequence_data = self.data.iloc[idx: idx + self.sequence_length]\n",
        "#         # images = [self.preprocessed_images[str(id)] for id in sequence_data[\"Id\"]]\n",
        "#         # out_image = self.preprocessed_images[str(idx+10)]\n",
        "#         # sample_input = {\n",
        "#         #     \"image\": torch.stack(images),\n",
        "#         #     \"outimage\": out_image,\n",
        "#         #     \"relative_time\": torch.tensor(sequence_data[\"Relative_Time\"].to_numpy(), dtype=torch.float32),\n",
        "#         #     \"time_diff\": torch.tensor(sequence_data[\"Time_Diff\"].to_numpy(), dtype=torch.float32),\n",
        "#         #     \"wind_speed\": torch.tensor(sequence_data[\"Wind_Speed\"].to_numpy(), dtype=torch.float32),\n",
        "#         # }\n",
        "\n",
        "#         # return sample_input\n",
        "#     def __getitem__(self, idx):\n",
        "#         # 检查索引是否有效\n",
        "#         if idx + self.sequence_length + 1 > len(self.data):\n",
        "#             return {\n",
        "#                 \"image\": torch.tensor([]),\n",
        "#                 \"outimage\": torch.tensor([]),\n",
        "#                 \"relative_time\": torch.tensor([]),\n",
        "#                 \"time_diff\": torch.tensor([]),\n",
        "#                 \"wind_speed\": torch.tensor([]),\n",
        "#             }\n",
        "\n",
        "#         sequence_data = self.data.iloc[idx: idx + self.sequence_length]\n",
        "#         images = [self.preprocessed_images[str(id)] for id in sequence_data[\"Id\"]]\n",
        "\n",
        "#         # 获取输出图像\n",
        "#         out_image_idx = idx + self.sequence_length\n",
        "#         if str(out_image_idx) not in self.preprocessed_images:\n",
        "#             return {\n",
        "#                 \"image\": torch.tensor([]),\n",
        "#                 \"outimage\": torch.tensor([]),\n",
        "#                 \"relative_time\": torch.tensor([]),\n",
        "#                 \"time_diff\": torch.tensor([]),\n",
        "#                 \"wind_speed\": torch.tensor([]),\n",
        "#             }\n",
        "#         out_image = self.preprocessed_images[str(out_image_idx)]\n",
        "\n",
        "#         sample_input = {\n",
        "#             \"image\": torch.stack(images),\n",
        "#             \"outimage\": out_image,\n",
        "#             \"relative_time\": torch.tensor(sequence_data[\"Relative_Time\"].to_numpy(), dtype=torch.float32),\n",
        "#             \"time_diff\": torch.tensor(sequence_data[\"Time_Diff\"].to_numpy(), dtype=torch.float32),\n",
        "#             \"wind_speed\": torch.tensor(sequence_data[\"Wind_Speed\"].to_numpy(), dtype=torch.float32),\n",
        "#         }\n",
        "\n",
        "#         return sample_input\n",
        "\n",
        "\n",
        "#     def __str__(self):\n",
        "#         class_string = self.__class__.__name__ + \"\\n\\tlen : %d\" % self.__len__()\n",
        "#         for key, value in self.__dict__.items():\n",
        "#             if key not in [\"data\", \"preprocessed_images\"]:\n",
        "#                 class_string += \"\\n\\t\" + str(key) + \" : \" + str(value)\n",
        "#         return class_string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YhQE9q4qLzn"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataloader import default_collate\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    # 过滤掉包含零大小张量的批次\n",
        "    batch = [b for b in batch if b['image'].nelement() != 0]\n",
        "    if len(batch) == 0:\n",
        "        return None\n",
        "    return default_collate(batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvNQ3OWVqLzn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "c2206386-feea-41f4-8e6f-cf28a365589e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "StormDataset.__init__() got an unexpected keyword argument 'root'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1787c8a3f71d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bkh'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStormDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_collate_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: StormDataset.__init__() got an unexpected keyword argument 'root'"
          ]
        }
      ],
      "source": [
        "# root_dir = '/Users/tl723/Downloads/imperial/youlanda2/storm/'\n",
        "storm = 'bkh'\n",
        "sequence_length = 10\n",
        "dataset = StormDataset(root=root_dir, storm=storm, sequence_length=sequence_length)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "dataloader = DataLoader(dataset, batch_size=5, shuffle=True, collate_fn=custom_collate_fn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsV24konqLzn"
      },
      "outputs": [],
      "source": [
        "# 展示 DataLoader 的基本信息\n",
        "print(\"DataLoader Information:\")\n",
        "print(\"-----------------------\")\n",
        "print(f\"Batch Size: {dataloader.batch_size}\")\n",
        "print(f\"Dataset Size: {len(dataloader.dataset)}\")\n",
        "print(f\"Number of Batches: {len(dataloader)}\")  # 迭代次数\n",
        "\n",
        "# 展示一个批次的数据\n",
        "for i, batch in enumerate(dataloader):\n",
        "    if batch['image'].nelement() == 0:  # 跳过无效批次\n",
        "        continue\n",
        "    print(\"\\nSample Batch:\")\n",
        "    print(\"-------------\")\n",
        "    print(\"Images Shape:\", batch['image'].shape)\n",
        "    print(\"Out Image Shape:\", batch['outimage'].shape)\n",
        "    print(\"Relative Time Shape:\", batch['relative_time'].shape)\n",
        "    print(\"Time Difference Shape:\", batch['time_diff'].shape)\n",
        "    print(\"Wind Speed Shape:\", batch['wind_speed'].shape)\n",
        "    # 只展示一个批次的数据\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIIrSIYeqLzo"
      },
      "outputs": [],
      "source": [
        "# resnet50\n",
        "# class STA_LSTM(nn.Module):\n",
        "#     def __init__(self, in_dim, sequence_length, lstm_in_dim, lstm_hidden_dim, cnn_feature_dim, out_dim, use_gpu=False):\n",
        "#         super(STA_LSTM, self).__init__()\n",
        "\n",
        "#         # 参数导入部分\n",
        "#         self.in_dim = in_dim\n",
        "#         self.sequence_length = sequence_length\n",
        "#         self.lstm_in_dim = lstm_in_dim\n",
        "#         self.lstm_hidden_dim = lstm_hidden_dim\n",
        "#         self.cnn_feature_dim = cnn_feature_dim\n",
        "#         self.out_dim = out_dim\n",
        "#         self.use_gpu = use_gpu\n",
        "\n",
        "#         # CNN特征提取器\n",
        "#         self.cnn_extractor = models.resnet50(pretrained=True)\n",
        "#         for param in self.cnn_extractor.parameters():\n",
        "#             param.requires_grad = False\n",
        "#         self.fitlinear = nn.Linear(1000,1024)\n",
        "\n",
        "#         # 网络结构部分\n",
        "#         self.batch_norm = nn.BatchNorm1d(in_dim)\n",
        "#         self.layer_in = nn.Linear(in_dim, in_dim, bias=False)\n",
        "#         self.S_A = nn.Linear(lstm_in_dim, lstm_in_dim)\n",
        "#         self.lstmcell = nn.LSTMCell(cnn_feature_dim, lstm_hidden_dim)\n",
        "#         self.T_A = nn.Linear(sequence_length * lstm_hidden_dim, sequence_length)\n",
        "#         self.layer_out = nn.Linear(lstm_hidden_dim, out_dim, bias=False)\n",
        "\n",
        "\n",
        "#         self.decoder = nn.Sequential(\n",
        "#             nn.ConvTranspose2d(lstm_hidden_dim, 256, kernel_size=4, stride=2, padding=1),  # 256x2x2\n",
        "#             nn.ReLU(),\n",
        "#             nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # 128x4x4\n",
        "#             nn.ReLU(),\n",
        "#             nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # 64x8x8\n",
        "#             nn.ReLU(),\n",
        "#             nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),  # 32x16x16\n",
        "#             nn.ReLU(),\n",
        "#             nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),  # 16x32x32\n",
        "#             nn.ReLU(),\n",
        "#             nn.ConvTranspose2d(16, 8, kernel_size=4, stride=2, padding=1),  # 8x64x64\n",
        "#             nn.ReLU(),\n",
        "#             nn.ConvTranspose2d(8, 4, kernel_size=4, stride=2, padding=1),  # 4x128x128\n",
        "#             nn.ReLU(),\n",
        "#             nn.ConvTranspose2d(4, 2, kernel_size=4, stride=2, padding=1),  # 2x256x256\n",
        "#             nn.ReLU(),\n",
        "#             nn.ConvTranspose2d(2, 3, kernel_size=4, stride=2, padding=1),  # 3x512x512\n",
        "#             nn.ReLU(),\n",
        "#             nn.ConvTranspose2d(3, 3, kernel_size=2, stride=1, padding=0),  # 3x511x511\n",
        "#             nn.ReLU(),\n",
        "#             # 裁剪层以精确匹配目标尺寸\n",
        "#             nn.Conv2d(3, 3, kernel_size=1, stride=1, padding=0)  # 调整为最终尺寸\n",
        "#         )\n",
        "\n",
        "#         # 添加一个裁剪操作\n",
        "#         self.crop = lambda x: x[:, :, :366, :366]\n",
        "\n",
        "#         # 激活函数\n",
        "#         self.sigmoid = nn.Sigmoid()\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "#     def forward(self, input_images):\n",
        "#         batch_size, sequence_length, C, H, W = input_images.size()\n",
        "#         cnn_input = input_images.view(batch_size * sequence_length, C, H, W)\n",
        "#         features = self.cnn_extractor(cnn_input)\n",
        "#         features = self.fitlinear(features)\n",
        "#         features = features.view(batch_size, sequence_length, -1)\n",
        "\n",
        "#         # 初始化隐藏状态和记忆单元\n",
        "#         h_t_1 = torch.zeros(batch_size, self.lstm_hidden_dim)\n",
        "#         c_t_1 = torch.zeros(batch_size, self.lstm_hidden_dim)\n",
        "#         if self.use_gpu:\n",
        "#             h_t_1 = h_t_1.cuda()\n",
        "#             c_t_1 = c_t_1.cuda()\n",
        "\n",
        "#         h_list = []\n",
        "#         for i in range(sequence_length):\n",
        "#             x_t = features[:, i, :]\n",
        "#             alpha_t = self.sigmoid(self.S_A(x_t))\n",
        "#             alpha_t = self.softmax(alpha_t)\n",
        "\n",
        "#             h_t, c_t = self.lstmcell(x_t * alpha_t, (h_t_1, c_t_1))\n",
        "#             h_list.append(h_t)\n",
        "\n",
        "#             h_t_1, c_t_1 = h_t, c_t\n",
        "\n",
        "#         total_ht = torch.cat(h_list, dim=1)\n",
        "#         beta_t = self.relu(self.T_A(total_ht))\n",
        "#         beta_t = self.softmax(beta_t)\n",
        "\n",
        "#         out = torch.zeros(batch_size, self.lstm_hidden_dim).cuda() if self.use_gpu else torch.zeros(batch_size, self.lstm_hidden_dim)\n",
        "#         for i in range(len(h_list)):\n",
        "#             out = out + h_list[i] * beta_t[:, i].unsqueeze(1)\n",
        "\n",
        "#         out = out.view(batch_size, self.lstm_hidden_dim, 1, 1)\n",
        "#         # print('outsize', out.shape())\n",
        "#         out = self.decoder(out)\n",
        "#         out = self.crop(out)\n",
        "#         return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVu2Sb54qLzo"
      },
      "outputs": [],
      "source": [
        "#resnet18\n",
        "class STA_LSTM(nn.Module):\n",
        "    def __init__(self, in_dim, sequence_length, lstm_in_dim, lstm_hidden_dim, cnn_feature_dim, out_dim, use_gpu=False):\n",
        "        super(STA_LSTM, self).__init__()\n",
        "\n",
        "        # 参数导入部分\n",
        "        self.in_dim = in_dim\n",
        "        self.sequence_length = sequence_length\n",
        "        self.lstm_in_dim = lstm_in_dim\n",
        "        self.lstm_hidden_dim = lstm_hidden_dim\n",
        "        self.cnn_feature_dim = cnn_feature_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.use_gpu = use_gpu\n",
        "\n",
        "        # CNN特征提取器\n",
        "        self.cnn_extractor = models.resnet18(pretrained=True)\n",
        "        self.cnn_extractor.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)  # 修改第一个卷积层以接受1个通道\n",
        "        for param in self.cnn_extractor.parameters():\n",
        "            param.requires_grad = False\n",
        "        # 调整fitlinear层以匹配resnet18的输出维度（resnet18的全连接层输出维度为512）\n",
        "        self.fitlinear = nn.Linear(1000, 1024)\n",
        "\n",
        "        # 网络结构部分\n",
        "        self.batch_norm = nn.BatchNorm1d(in_dim)\n",
        "        self.layer_in = nn.Linear(in_dim, in_dim, bias=False)\n",
        "        self.S_A = nn.Linear(lstm_in_dim, lstm_in_dim)\n",
        "        self.lstmcell = nn.LSTMCell(cnn_feature_dim, lstm_hidden_dim)\n",
        "        self.T_A = nn.Linear(sequence_length * lstm_hidden_dim, sequence_length)\n",
        "        self.layer_out = nn.Linear(lstm_hidden_dim, out_dim, bias=False)\n",
        "\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 256, kernel_size=4, stride=2, padding=1),  # 第1层\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # 第2层\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # 第3层\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),  # 第4层\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),  # 第5层\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 8, kernel_size=4, stride=2, padding=1),  # 第6层\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(8, 4, kernel_size=4, stride=2, padding=1),  # 第7层\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(4, 2, kernel_size=4, stride=2, padding=1),  # 第8层\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(2, 1, kernel_size=4, stride=2, padding=1),  # 第9层，输出变为单通道\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(1, 1, kernel_size=1, stride=1, padding=0)  # 最终尺寸调整层，确保输出尺寸为1x128x128\n",
        "        )\n",
        "\n",
        "\n",
        "        # 更新裁剪操作以适配128x128\n",
        "        self.crop = lambda x: x[:, :, :128, :128]\n",
        "\n",
        "        # 激活函数\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, input_images):\n",
        "        batch_size, sequence_length, C, H, W = input_images.size()\n",
        "        cnn_input = input_images.view(batch_size * sequence_length, C, H, W)\n",
        "        features = self.cnn_extractor(cnn_input)\n",
        "        features = self.fitlinear(features)\n",
        "        features = features.view(batch_size, sequence_length, -1)\n",
        "\n",
        "        # 初始化隐藏状态和记忆单元\n",
        "        h_t_1 = torch.zeros(batch_size, self.lstm_hidden_dim)\n",
        "        c_t_1 = torch.zeros(batch_size, self.lstm_hidden_dim)\n",
        "        if self.use_gpu:\n",
        "            h_t_1 = h_t_1.cuda()\n",
        "            c_t_1 = c_t_1.cuda()\n",
        "\n",
        "        h_list = []\n",
        "        for i in range(sequence_length):\n",
        "            x_t = features[:, i, :]\n",
        "            alpha_t = self.sigmoid(self.S_A(x_t))\n",
        "            alpha_t = self.softmax(alpha_t)\n",
        "\n",
        "            h_t, c_t = self.lstmcell(x_t * alpha_t, (h_t_1, c_t_1))\n",
        "            h_list.append(h_t)\n",
        "\n",
        "            h_t_1, c_t_1 = h_t, c_t\n",
        "\n",
        "        total_ht = torch.cat(h_list, dim=1)\n",
        "        beta_t = self.relu(self.T_A(total_ht))\n",
        "        beta_t = self.softmax(beta_t)\n",
        "\n",
        "        out = torch.zeros(batch_size, self.lstm_hidden_dim).cuda() if self.use_gpu else torch.zeros(batch_size, self.lstm_hidden_dim)\n",
        "        for i in range(len(h_list)):\n",
        "            out = out + h_list[i] * beta_t[:, i].unsqueeze(1)\n",
        "\n",
        "        out = out.view(batch_size, self.lstm_hidden_dim, 1, 1)\n",
        "        # print('outsize', out.shape())\n",
        "        out = self.decoder(out)\n",
        "        out = self.crop(out)\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llyfLAxYqLzo"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# 定义损失函数和优化器\n",
        "model = STA_LSTM(in_dim=1024, sequence_length=10, lstm_in_dim=1024, lstm_hidden_dim=256, cnn_feature_dim=1024, out_dim=1, use_gpu=False)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# 训练循环\n",
        "num_epochs = 10  # 根据需要调整\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        if batch['image'].nelement() == 0:  # 跳过无效批次\n",
        "            continue\n",
        "        inputs = batch['image']\n",
        "        targets = batch['outimage']\n",
        "        if model.use_gpu:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        # 前向传播\n",
        "        outputs = model(inputs)\n",
        "        # print(inputs.shape)\n",
        "        # print(targets.shape)\n",
        "        # print(outputs.shape)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # 反向传播和优化\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        # print('*',running_loss / len(dataloader))\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "# 保存模型\n",
        "torch.save(model.state_dict(), 'model.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTBcygoWqLzo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def show_image(image_tensor):\n",
        "    \"\"\"\n",
        "    显示模型预测的图像。\n",
        "    参数:\n",
        "        image_tensor (torch.Tensor): 预测的图像张量，形状为 [1, channels, height, width].\n",
        "    \"\"\"\n",
        "    # 检查图像张量的形状\n",
        "    # if image_tensor.ndim != 4 or image_tensor.shape[0] != 1:\n",
        "    #     raise ValueError(\"图像张量应该有一个形状为 [1, channels, height, width]\")\n",
        "\n",
        "    # 将图像张量转换回PIL图像以进行显示\n",
        "    transform = transforms.ToPILImage()\n",
        "    image = transform(image_tensor.squeeze(0))  # 移除批量维度\n",
        "\n",
        "    # 显示图像\n",
        "    plt.imshow(image, cmap='gray')  # 如果是RGB图像，移除 cmap 参数\n",
        "    plt.axis('off')  # 不显示坐标轴\n",
        "    plt.show()\n",
        "\n",
        "# 假设 prediction 是你的预测图像张量\n",
        "# show_image(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dby9dQQmqLzp"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataloader, device='cpu'):\n",
        "    \"\"\"\n",
        "    评估模型并生成图像。\n",
        "    参数:\n",
        "        model: 训练好的模型。\n",
        "        dataloader: 用于评估的数据加载器。\n",
        "        device: 运行模型的设备（'cpu' 或 'cuda'）。\n",
        "    \"\"\"\n",
        "    model.eval()  # 将模型置于评估模式\n",
        "    model.to(device)\n",
        "\n",
        "    with torch.no_grad():  # 禁用梯度计算\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            inputs = batch['image'].to(device)\n",
        "            targets = batch['outimage'].to(device)\n",
        "            print(targets.shape)\n",
        "            # 前向传播，生成图像\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # 可选：显示或保存图像\n",
        "            # 假设我们只显示/保存第一个图像\n",
        "            predicted_image = outputs[0].cpu()  # 将图像移回CPU\n",
        "            print(predicted_image)\n",
        "            show_image(predicted_image)  # 使用之前定义的显示函数\n",
        "            show_image(targets[0])\n",
        "            # 如果只想处理一个批次，可以在这里中断循环\n",
        "            break\n",
        "\n",
        "# 加载训练好的模型\n",
        "model = STA_LSTM(in_dim=1024, sequence_length=10, lstm_in_dim=1024, lstm_hidden_dim=256, cnn_feature_dim=1024, out_dim=1, use_gpu=False)\n",
        "model.load_state_dict(torch.load('model.pth'))\n",
        "\n",
        "# 评估模型\n",
        "evaluate_model(model, dataloader)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dsml4p",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}